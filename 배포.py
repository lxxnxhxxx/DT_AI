import streamlit as st
import zipfile
import os
import json
import google.generativeai as genai
import tempfile

# Gemini API ì„¤ì •
genai.configure(api_key="AIzaSyA6m8hPy_mCEOkOZ3YsrUEEqbs376N3Lwc")
model = genai.GenerativeModel("gemini-1.5-flash")

st.title("ğŸ“„ JSON/ZIP ê¸°ë°˜ ë…¼ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ")

uploaded_file = st.file_uploader(
    "ë…¼ë¬¸ JSON íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ZIP ë˜ëŠ” JSON)",
    type=["zip", "json"]
)
question = st.text_input("AIì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

ask = st.button("ì§ˆë¬¸í•˜ê¸°")

if uploaded_file and question and ask:
    try:
        context_list = []

        with tempfile.TemporaryDirectory() as temp_dir:
            # ZIP íŒŒì¼ ì²˜ë¦¬
            if uploaded_file.type == "application/zip" or uploaded_file.name.lower().endswith(".zip"):
                with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
                    zip_ref.extractall(temp_dir)
                paths = [
                    os.path.join(temp_dir, fn)
                    for fn in os.listdir(temp_dir)
                    if fn.lower().endswith(".json")
                ]
            # ë‹¨ì¼ JSON ì²˜ë¦¬
            else:
                path = os.path.join(temp_dir, uploaded_file.name)
                with open(path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                paths = [path]

            # ê° JSON íŒŒì‹±
            for p in paths:
                with open(p, "r", encoding="utf-8") as f:
                    data = json.load(f)

                # sections ìœ„ì¹˜ íŒë³„
                if isinstance(data.get("packages"), dict):
                    # ê¸°ì¡´ êµ¬ì¡°: data["packages"]["gpt"]["sections"]
                    sections = (
                        data["packages"].get("gpt", {})
                                        .get("sections", {})
                    )
                else:
                    # ìƒˆ êµ¬ì¡°: data["sections"]
                    sections = data.get("sections", {})

                title       = sections.get("title", "")
                abstract    = sections.get("abstract", "")
                methodology = sections.get("methodology", "")
                results     = sections.get("results", "")

                context_list.append(
                    f"ğŸ“„ ì œëª©: {title}\n\n"
                    f"[ì´ˆë¡]\n{abstract}\n\n"
                    f"[ë°©ë²•ë¡ ]\n{methodology}\n\n"
                    f"[ê²°ê³¼]\n{results}"
                )

        full_context = "\n\n---\n\n".join(context_list)

        prompt = f"""
ë‹¤ìŒì€ ì—¬ëŸ¬ ë…¼ë¬¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.

{full_context}

[ì§ˆë¬¸]
{question}
"""

        response = model.generate_content(prompt)
        st.subheader("ğŸ§  AIì˜ ì‘ë‹µ:")
        st.write(response.text)

    except Exception as e:
        st.error(f"â— ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
